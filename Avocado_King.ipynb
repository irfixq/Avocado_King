{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avocado_King.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMlGdmURtrfFGLp7J8M8KAg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irfixq/Avocado_King/blob/main/Avocado_King.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N37HxWnw2Ln"
      },
      "source": [
        "# Avocado King - Avocado Price & Sales Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZmttJ6Zb4Tt"
      },
      "source": [
        "## System Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_LgmTIRwhSn"
      },
      "source": [
        "import sys #access to system parameters https://docs.python.org/3/library/sys.html\r\n",
        "\r\n",
        "import numpy as np # linear algebra\r\n",
        "\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "\r\n",
        "import matplotlib # collection of functions for scientific and publication-ready visualization\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import seaborn as sns # visualizing distributions data\r\n",
        "from scipy import stats # visualizing probability distribution of statistical function\r\n",
        "\r\n",
        "import warnings # ignore warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "from google.colab import data_table # to show full data table in multiple pages\r\n",
        "%load_ext google.colab.data_table\r\n",
        "pd.set_option('max_rows', 30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJsfghPbscM"
      },
      "source": [
        "## Check system and python dependencies version\r\n",
        "print(\"Python version: {}\". format(sys.version))\r\n",
        "print(\"NumPy version: {}\". format(np.__version__))\r\n",
        "print(\"pandas version: {}\". format(pd.__version__))\r\n",
        "print(\"matplotlib version: {}\". format(matplotlib.__version__))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OYOXbyezrvc"
      },
      "source": [
        "There are 2 options to get the data, either from GitHub or Google Drive.\r\n",
        "In this case, I prefer to use Git Clone since it will be easier for user to access the repo instead of loading everything into their Google Drive or local."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flmH4nz0zgkI"
      },
      "source": [
        "## Clone repo from GitHub\r\n",
        "! git clone 'https://github.com/irfixq/Avocado_King'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBSvyvrexLww"
      },
      "source": [
        "## Mount Google Drive to get data\r\n",
        "## make sure you uploaded the folder into your Google Drive first\r\n",
        "\r\n",
        "#from google.colab import drive \r\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ188A0N0bNZ"
      },
      "source": [
        "## get working directory\r\n",
        "! pwd\r\n",
        "\r\n",
        "## list all folders in working directory\r\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVhfHnGoxzZe"
      },
      "source": [
        "## change working directory to github folder\r\n",
        "import os\r\n",
        "os.chdir('/content/Avocado_King')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo7MTdcj1x2G"
      },
      "source": [
        "## check working directory after change path\r\n",
        "! pwd\r\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ-yd4G3w0ID"
      },
      "source": [
        "## Data Pre-Processing\r\n",
        "\r\n",
        "1. Data pre-processing for price and sales data\r\n",
        "> * Read dataset  as pandas dataframe\r\n",
        "> * Check for df dimension (rows, columns)\r\n",
        "> * Check for column names and datatype\r\n",
        "> * Show raw dataset table\r\n",
        "> * Check for missing values\r\n",
        "> * Handle missing values (if any)\r\n",
        "\r\n",
        "\r\n",
        "2. Data Distribution\r\n",
        "3. Data pre-processing for Google search data\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCRmV_Y8_2Sa"
      },
      "source": [
        "#### Data pre-processing for price and sales data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae1To9FQw05Y"
      },
      "source": [
        "## see the shape of the dataset (rows, columns)\r\n",
        "df_price = pd.read_csv('/content/Avocado_King/price-and-sales-data.csv')\r\n",
        "df_price.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck_DDBfK21_-"
      },
      "source": [
        "## list all column names\r\n",
        "df_price.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DA953y8_ia-"
      },
      "source": [
        "## checking data type of each column\r\n",
        "df_price.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy7qD4a92Qdg"
      },
      "source": [
        "## see the dataset\r\n",
        "df_price.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej5WC2SK-tmd"
      },
      "source": [
        "## check for missing values in dataset\n",
        "print(f\"Missing data:{df_price.isna().sum(axis=0).any()}\") # TRUE represents the dataset has missing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EERQLxqv43SE"
      },
      "source": [
        "## see distribution of missing values in heat map\r\n",
        "sns.heatmap(df_price.isna(),cmap='Greens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XMsz6SD5RxJ"
      },
      "source": [
        "Based on heatmap above, \r\n",
        "the dark marks represent missing values in our dataset. Column 'Date', 'type', 'year', 'region' does not have any missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRq1tJ8zmiSN"
      },
      "source": [
        "## See the missing data in dataset\r\n",
        "df_price_NA_check = df_price.isna()\r\n",
        "df_price_NA_check.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLYwXEMZeHDu"
      },
      "source": [
        "## Save as new .csv table to see whole data / for download\r\n",
        "df_price_NA_check.to_csv('df_price_NA_check.csv',sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tm1NIip_75m"
      },
      "source": [
        "## there are 2 option to handle missing data\r\n",
        "# option 1 = eliminate data point that contain missing values (not recommended as you might missed important data for other attribute)\r\n",
        "# option 2 = substitue missing value with avg value of the attribute\r\n",
        "\r\n",
        "dfnew_price = df_price.fillna(df_price.mean())\r\n",
        "dfnew_price.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z_NpGk0AiGa"
      },
      "source": [
        "## check for dataset after impute missing values\r\n",
        "print(f\"Missing data:{dfnew_price.isna().sum(axis=0).any()}\")  # FALSE represent there is no missing values anymore in the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7SddHUVAsYq"
      },
      "source": [
        "## see new dataset after substitue missing values / for download\r\n",
        "dfnew_price.to_csv('dfnew_price.csv',sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOU6_FQalC0L"
      },
      "source": [
        "## Check for outliers\r\n",
        "outliers = dfnew_price.describe()\r\n",
        "outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1CUxiVoZxM"
      },
      "source": [
        "Based on above table, there is no outliers within the dataset because all mean values lie in between min and max values of the distribution.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjo4jFW6nyk-"
      },
      "source": [
        "## Save as new .csv file / for download\r\n",
        "outliers.to_csv('outliers.csv',sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XDdftWvhcby"
      },
      "source": [
        "## Check for duplicate values in dataset\r\n",
        "print('Duplicated values = ',sum(dfnew_price.duplicated()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awGUWUhL5h6m"
      },
      "source": [
        "## Checking each features of the cleaned dataset\r\n",
        "dfnew_price.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQl-8qeZCg5A"
      },
      "source": [
        "## see distribution of cleaned dataset in heat map\r\n",
        "sns.heatmap(dfnew_price.isna(),cmap='Greens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja8NXbSX5wvR"
      },
      "source": [
        "**Conclusion after data pre-processing**\r\n",
        "* Features = 13\r\n",
        "* Instances = 25,161\r\n",
        "* No duplicate values\r\n",
        "* No null values after imputing the missing values with mean of the attribute itself\r\n",
        "* Features with datatype = 'object' could be the machine learning classifier which are; 'type' & 'region'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8frkpZEBD4E"
      },
      "source": [
        "#### Data Distribution\r\n",
        "To understand how the variables are distributed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRkhf2kgF6sS"
      },
      "source": [
        "##### Visualizing Data Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCVwPBlByt98"
      },
      "source": [
        "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(12,10))\r\n",
        "# Univriate distribution plot\r\n",
        "# by default the kernel density estimation is TRUE; to see continuous density by smoothing the observation using Gaussian kernel fx\r\n",
        "sns.distplot(dfnew_price.AveragePrice, color='green', ax=ax[0])\r\n",
        "# Box plot\r\n",
        "sns.boxplot(dfnew_price.AveragePrice, color='green',ax=ax[1])\r\n",
        "\r\n",
        "## see probability distribution of avg price\r\n",
        "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,5))\r\n",
        "# Probability distribution\r\n",
        "stats.probplot(dfnew_price['AveragePrice'], plot=ax)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOayGA3oyxK3"
      },
      "source": [
        "**Conclusion from visualizing the data distribution**\r\n",
        "* All 3 plots above showed bimodal distribution which telling us that we have 2 local maximum.\r\n",
        "* As discussed earlier in pre-processing section, our potential classifier could be Type and Region which in this case Type has 2 class (Organic & Conventional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH4m29CyBAyU"
      },
      "source": [
        "# Bivariate distribution plot of average price against total volume for each avocade type (class: Organic & Conventional)\r\n",
        "sns.displot(dfnew_price, x='TotalVolume', y='AveragePrice',hue='type',height=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xumuIdrcDrNp"
      },
      "source": [
        "# Bivariate distribution plot of average price against total volume for all region\r\n",
        "sns.displot(dfnew_price, x='TotalVolume', y='AveragePrice',hue='region',height=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st1_b-2EpATw"
      },
      "source": [
        "**Conclusion from Bivariate Distribution plot**\r\n",
        "* Based on the bivariate distribution plot above, we can see that more conventional avocado has been sold compared to organic avocado.\r\n",
        "* Also, organic avocado was selling at higher price compared to conventional avocado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjUhk7u7ziT3"
      },
      "source": [
        "**Skewness**\r\n",
        "* Measure of the asymmetry of the probability distribution of a random variable about its mean. In other words, skewness tells you the amount and direction of skew (departure from horizontal symmetry)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSXJtlqKDQRz"
      },
      "source": [
        "print(\"Skewness: %f\" % dfnew_price['AveragePrice'].skew())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0LxliFGWCt"
      },
      "source": [
        "* If skewness is 0, the data are perfectly symmetrical, although it is quite unlikely for real-world data.\r\n",
        "* If skewness is less than -1 or greater than 1, the distribution is highly skewed.\r\n",
        "***If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.**\r\n",
        "* If skewness is between -0.5 and 0.5, the distribution is approximately symmetric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueVcxvfxf3Tg"
      },
      "source": [
        "**Kurtosis**\r\n",
        "* Measure the heaviness of distribution tails w.r.t. skewness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNJAh57Czhvj"
      },
      "source": [
        "## Kurtosis: Measure heaviness of the distribution tails\r\n",
        "print(\"Kurtosis: %f\" % dfnew_price['AveragePrice'].kurt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUyLkyp-MIxV"
      },
      "source": [
        "* Positive value means more data in the tail of the distribution.\r\n",
        "* Excess kurtosis = kurtosis - 3 = -2.442; which represent that we have lighter tail than normal distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDwiWV4UfVsi"
      },
      "source": [
        "##### Classifiers\r\n",
        "\r\n",
        "We have identified potential classifiers to be 'type' and 'region'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ig1MNKlJIwV"
      },
      "source": [
        "df_conv_avo = dfnew_price[dfnew_price['type'] == 'conventional']\r\n",
        "print(\"Conventional Avocado = \",df_conv_avo.shape)\r\n",
        "\r\n",
        "df_org_avo = dfnew_price[dfnew_price['type'] == 'organic']\r\n",
        "print(\"Organic Avocado = \",df_org_avo.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQVcFXwRO94X"
      },
      "source": [
        "## Create histogram to see data distribution of both class in 'type'\r\n",
        "\r\n",
        "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 7))\r\n",
        "sns.distplot(df_conv_avo['AveragePrice'],color='brown') # conventional avocado\r\n",
        "sns.distplot(df_org_avo['AveragePrice'],color='darkgreen') # organic avocado\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaB2uI0FcmXL"
      },
      "source": [
        "## Calculate 'Measure of Spread' for AveragePrice of the CONVENTIONAL avocado dataset\r\n",
        "df_conv_avo['AveragePrice'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9eqJpH2dzPY"
      },
      "source": [
        "## Calculate 'Measure of Spread' for AveragePrice of the ORGANIC avocado dataset\r\n",
        "df_org_avo['AveragePrice'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEwS1jWve3Fh"
      },
      "source": [
        "Visualize the 'Measure of Spread' calculated for AveragePrice of both class using Boxplot function.\r\n",
        "https://www.statisticshowto.com/probability-and-statistics/descriptive-statistics/box-plot/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzByDRijRWq5"
      },
      "source": [
        "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\r\n",
        "sns.boxplot(x='type',y='AveragePrice',data=dfnew_price,palette='Greens',showmeans=True)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Can also visualize in combined boxplot by running below code\r\n",
        "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,8))\r\n",
        "sns.boxplot(df_conv_avo['AveragePrice'],color='brown')\r\n",
        "sns.boxplot(df_org_avo['AveragePrice'],color='darkgreen')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iPh4_FcUY3u"
      },
      "source": [
        "conventional = dfnew_price['type']=='conventional'\r\n",
        "organic = dfnew_price['type']=='organic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhqkHekuWXY6"
      },
      "source": [
        "## Average price of CONVENTIONAL avocado in each year by region\r\n",
        "conv_price_byyear_byregion = sns.factorplot('AveragePrice','region',data=dfnew_price[conventional],hue='year',size=10,palette='bright',join=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3smuwgHWRKl"
      },
      "source": [
        "## Average price of ORGANIC avocado in each year by region\r\n",
        "organic_price_byyear_byregion = sns.factorplot('AveragePrice','region',data=dfnew_price[organic],hue='year',size=10,palette='bright',join=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhklJqsgWnwq"
      },
      "source": [
        "## Average price of conventional avocado by region (average from year 2015-2019)\r\n",
        "conventional_factorplot = sns.factorplot('AveragePrice','region',data=dfnew_price[conventional],color='brown',size=10,join=False,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNyR0BxMSHUK"
      },
      "source": [
        "## Average price of organic avocado by region (average from year 2015-2019)\r\n",
        "organic_factorplot = sns.factorplot('AveragePrice','region',data=dfnew_price[organic],color='darkgreen',size=10,join=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPuH6dBPgPLe"
      },
      "source": [
        "**Conclusion**\r\n",
        "* Not only class 'type' that affect the average price but also 'region'.\r\n",
        "* \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ESsHWdLgnSm"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Fn2Dl_g0V8"
      },
      "source": [
        "#corrmat = dfnew_price.corr()\r\n",
        "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(14, 10))\r\n",
        "#ax.set_title(\"Correlation Matrix\", fontsize=20)\r\n",
        "sns.heatmap(dfnew_price.corr(), vmin=-1, vmax=1, cmap='RdYlGn', annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd55tGXviY0e"
      },
      "source": [
        "**Conclusion from feature extraction**\r\n",
        "* TotalVolume and TotalBags show strongest correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OAELeGBQvu_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcqd_J_ZO5ge"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X = dfnew_price.drop(['AveragePrice','Date','type','region'],1)  # drop date column as model training split unable to convert Date to float (not suitable)\r\n",
        "y = dfnew_price['AveragePrice']  # dependent variable\r\n",
        "print('Shape of dataset = ', X.shape, y.shape)\r\n",
        "\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\r\n",
        "print('Shape of training dataset = ', X_train.shape, y_train.shape)\r\n",
        "print('Shape of test dataset = ', X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZabS9MSrCft4"
      },
      "source": [
        "X.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWwikZhQBKg1"
      },
      "source": [
        "## Prediction Machine Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmxN1qyQBNG-"
      },
      "source": [
        "from sklearn import linear_model\r\n",
        "lm = linear_model.LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grq8941zBzNA"
      },
      "source": [
        "model = lm.fit(X_train, y_train)\r\n",
        "predictions = lm.predict(X_test)\r\n",
        "\r\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxgKTiO4Dws7"
      },
      "source": [
        "## Plotting model\r\n",
        "\r\n",
        "plt.scatter(y_test, predictions)\r\n",
        "plt.xlabel('AveragePrice')\r\n",
        "plt.ylabel('Predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egnbK4i4D-54"
      },
      "source": [
        "## Check for accuracy\r\n",
        "print ('Accuracy score of Linear Regression model = ', model.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lryBHCxZH7ik"
      },
      "source": [
        "**another model**\r\n",
        "\r\n",
        "https://www.kaggle.com/mruanova/predict-avocado-prices-using-linear-regression/notebook#Step-6-Missing-Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KkG77t5EfCg"
      },
      "source": [
        "from scipy import stats\r\n",
        "\r\n",
        "X = dfnew_price.year\r\n",
        "y = dfnew_price['AveragePrice']\r\n",
        "\r\n",
        "slope, intercept, r, p, std_err = stats.linregress(X, y) # scipy\r\n",
        "\r\n",
        "def modelPrediction(x):\r\n",
        "  return slope * x + intercept\r\n",
        "\r\n",
        "model = list(map(modelPrediction, X)) # scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjxAmp9wNOsV"
      },
      "source": [
        "X_pred = 2020\r\n",
        "y_pred = modelPrediction(X_pred)\r\n",
        "print('Model Prediction of CONVENTIONAL avocado AveragePrice in 2020')\r\n",
        "avocado_price = round(y_pred, 2)\r\n",
        "print('$ {} USD'.format(avocado_price))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAurUkHYMdU2"
      },
      "source": [
        "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,8))\r\n",
        "\r\n",
        "plt.scatter(X, y,color='green',) # Scatter Plot\r\n",
        "plt.plot(X, model, color='red')\r\n",
        "plt.ylim(ymin=0) # starts at zero\r\n",
        "plt.xticks(np.arange(min(X), max(X)+1))\r\n",
        "plt.legend(['Model Prediction using Linear Regression', 'Conventional Avocado Prices (2015-2018)'])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JonBpRguQgin"
      },
      "source": [
        "model = lm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAZ_VwY1O0rw"
      },
      "source": [
        "## Check for accuracy\r\n",
        "print ('Accuracy score of Linear Regression model = ', model.score(X_pred, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4LITrEx86Gj"
      },
      "source": [
        "## Validation\r\n",
        "Our dataset is considered small enough and no single split is can give satisfactory variance in estimation. Hence, cross-validation of data is proposed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPceVaEKFbUz"
      },
      "source": [
        "from sklearn.model_selection import KFold \r\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgs-seMS9UmC"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.20)\r\n",
        "print('Shape of training dataset = ', X_train.shape, y_train.shape)\r\n",
        "print('Shape of test dataset = ', X_val.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLJIoBLlFcl-"
      },
      "source": [
        "kf = KFold(n_splits=10) # Define the split - into 2 folds \r\n",
        "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\r\n",
        "print(kf) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnXbzsmEG0GA"
      },
      "source": [
        "model = lm.fit(X_train, y_train)\r\n",
        "predictions_val = lm.predict(X_val)\r\n",
        "\r\n",
        "predictions_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI1pC11GG3gI"
      },
      "source": [
        "## Plotting model\r\n",
        "\r\n",
        "plt.scatter(y_val, predictions_val)\r\n",
        "plt.xlabel('AveragePrice')\r\n",
        "plt.ylabel('Predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6SvkHBSG0tF"
      },
      "source": [
        "## Check for accuracy\r\n",
        "print ('Accuracy score of Linear Regression model = ', model.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21YgYHWeHHTZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHwt9TrCHpCT"
      },
      "source": [
        "**Conclusion**\r\n",
        "* Model accuracy has improved after do cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP6lJmSKHx07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}